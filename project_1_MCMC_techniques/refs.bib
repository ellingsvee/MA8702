@article{roberts_rosenthal_2001,
  title = {Optimal scaling for various {Metropolis-Hastings} algorithms},
  author = {Roberts, Gareth O. and Rosenthal, Jeffrey S.},
  journal = {Statistical Science},
  volume = {16},
  number = {4},
  pages = {351--367},
  year = {2001},
  publisher = {Institute of Mathematical Statistics},
  doi = {10.1214/ss/1015346320},
}

@software{jax2018github,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James
            Johnson and Chris Leary and Dougal Maclaurin and George Necula and
            Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao
            Zhang},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/jax-ml/jax},
  version = {0.3.13},
  year = {2018},
}


@article{dunson_hastings_2020,
  title = {The {Hastings} algorithm at fifty},
  volume = {107},
  issn = {0006-3444},
  url = {https://doi.org/10.1093/biomet/asz066},
  doi = {10.1093/biomet/asz066},
  abstract = {In a 1970 Biometrika paper, W. K. Hastings developed a broad class
              of Markov chain algorithms for sampling from probability
              distributions that are difficult to sample from directly. The
              algorithm draws a candidate value from a proposal distribution and
              accepts the candidate with a probability that can be computed using
              only the unnormalized density of the target distribution, allowing
              one to sample from distributions known only up to a constant of
              proportionality. The stationary distribution of the corresponding
              Markov chain is the target distribution one is attempting to sample
              from. The Hastings algorithm generalizes the Metropolis algorithm
              to allow a much broader class of proposal distributions instead of
              just symmetric cases. An important class of applications for the
              Hastings algorithm corresponds to sampling from Bayesian posterior
              distributions, which have densities given by a prior density
              multiplied by a likelihood function and divided by a normalizing
              constant equal to the marginal likelihood. The marginal likelihood
              is typically intractable, presenting a fundamental barrier to
              implementation in Bayesian statistics. This barrier can be overcome
              by Markov chain Monte Carlo sampling algorithms. Amazingly, even
              after 50 years, the majority of algorithms used in practice today
              involve the Hastings algorithm. This article provides a brief
              celebration of the continuing impact of this ingenious algorithm on
              the 50th anniversary of its publication.},
  number = {1},
  urldate = {2026-01-06},
  journal = {Biometrika},
  author = {Dunson, D B and Johndrow, J E},
  month = mar,
  year = {2020},
  pages = {1--23},
  file = {Full Text PDF:/Users/ellingsv/Zotero/storage/MHE4IGGY/Dunson and
          Johndrow - 2020 - The Hastings algorithm at
          fifty.pdf:application/pdf;Snapshot:/Users/ellingsv/Zotero/storage/VPNXFGKL/asz066.html:text/html
          },
}

@article{matplotlib2007,
  Author = {Hunter, J. D.},
  Title = {Matplotlib: A 2D graphics environment},
  Journal = {Computing in Science \& Engineering},
  Volume = {9},
  Number = {3},
  Pages = {90--95},
  abstract = {Matplotlib is a 2D graphics package used for Python for
              application development, interactive scripting, and
              publication-quality image generation across user interfaces and
              operating systems.},
  publisher = {IEEE COMPUTER SOC},
  doi = {10.1109/MCSE.2007.55},
  year = 2007,
}

@misc{cabezas2024blackjax,
  title = {BlackJAX: Composable {B}ayesian inference in {JAX}},
  author = {Alberto Cabezas and Adrien Corenflos and Junpeng Lao and Rémi Louf},
  year = {2024},
  eprint = {2402.10797},
  archivePrefix = {arXiv},
  primaryClass = {cs.MS},
}

@article{carpenter2017stan,
  title = {Stan: A probabilistic programming language},
  author = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D and Lee,
            Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus
            and Guo, Jiqiang and Li, Peter and Riddell, Allen},
  journal = {Journal of statistical software},
  volume = {76},
  number = {1},
  year = {2017},
  publisher = {Columbia Univ., New York, NY (United States); Harvard Univ.,
               Cambridge, MA (United States)},
}



@misc{hoffman_no-u-turn_2011,
  title = {The {No}-{U}-{Turn} {Sampler}: {Adaptively} {Setting} {Path} {Lengths
           } in {Hamiltonian} {Monte} {Carlo}},
  shorttitle = {The {No}-{U}-{Turn} {Sampler}},
  url = {http://arxiv.org/abs/1111.4246},
  doi = {10.48550/arXiv.1111.4246},
  abstract = {Hamiltonian Monte Carlo (HMC) is a Markov chain Monte Carlo (MCMC)
              algorithm that avoids the random walk behavior and sensitivity to
              correlated parameters that plague many MCMC methods by taking a
              series of steps informed by first-order gradient information. These
              features allow it to converge to high-dimensional target
              distributions much more quickly than simpler methods such as random
              walk Metropolis or Gibbs sampling. However, HMC's performance is
              highly sensitive to two user-specified parameters: a step size ε
              and a desired number of steps L. In particular, if L is too small
              then the algorithm exhibits undesirable random walk behavior, while
              if L is too large the algorithm wastes computation. We introduce
              the No-U-Turn Sampler (NUTS), an extension to HMC that eliminates
              the need to set a number of steps L. NUTS uses a recursive
              algorithm to build a set of likely candidate points that spans a
              wide swath of the target distribution, stopping automatically when
              it starts to double back and retrace its steps. Empirically, NUTS
              perform at least as efficiently as and sometimes more efficiently
              than a well tuned standard HMC method, without requiring user
              intervention or costly tuning runs. We also derive a method for
              adapting the step size parameter ε on the fly based on primal-dual
              averaging. NUTS can thus be used with no hand-tuning at all. NUTS
              is also suitable for applications such as BUGS-style automatic
              inference engines that require efficient "turnkey" sampling
              algorithms.},
  urldate = {2026-02-06},
  publisher = {arXiv},
  author = {Hoffman, Matthew D. and Gelman, Andrew},
  month = nov,
  year = {2011},
  note = {arXiv:1111.4246 [stat]},
  keywords = {Computer Science - Machine Learning, Statistics - Computation},
  annote = {Comment: 30 pages, 7 figures},
  file = {Preprint PDF:/Users/ellingsv/Zotero/storage/7AWCJ3XQ/Hoffman and
          Gelman - 2011 - The No-U-Turn Sampler Adaptively Setting Path Lengths
          in Hamiltonian Monte
          Carlo.pdf:application/pdf;Snapshot:/Users/ellingsv/Zotero/storage/5DYJ5WKA/1111.html:text/html
          },
}

@article{Gabry_2019,
  title = {Visualization in Bayesian Workflow},
  volume = {182},
  ISSN = {1467-985X},
  url = {http://dx.doi.org/10.1111/rssa.12378},
  DOI = {10.1111/rssa.12378},
  number = {2},
  journal = {Journal of the Royal Statistical Society Series A: Statistics in
             Society},
  publisher = {Oxford University Press (OUP)},
  author = {Gabry, Jonah and Simpson, Daniel and Vehtari, Aki and Betancourt,
            Michael and Gelman, Andrew},
  year = {2019},
  month = jan,
  pages = {389–402},
}
